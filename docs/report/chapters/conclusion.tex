\chapter{Conclusion}
\label{ch:conclusion}

This report presented a description of a project that implements state-of-the-art text-independent Automatic Speaker Recognition (ASR) systems. Several techniques were analysed, since the feature extraction until the speaker modeling and the recognition tests.

Initially, the architectures for both types of ASR systems described (identification and verification) were introduced using a higher abstraction in \chapterref{speaker-recognition-systems}. Different ways to train and test the systems, along with the likelihood ratio test, were explained. \chapterref{feature-extraction} detailed the feature extraction process, describing the Mel-Frequency Cepstral Coefficient (MFCC) parametrization in its entirety, from the inspiration in the human ear and the concept of loudness to the Cepstral Mean Subtraction (CMS) and the delta coefficients techniques. The speaker representation discussed in \chapterref{gmm} was the Gaussian Mixture Model (GMM), a statistical model introduced in the field of speaker recognition more than 20 years ago, and popularized in in the beginning of the century. Along with the basic GMM, several variations were presented. The known Universal Background Model (UBM) and Adapted Gaussian Mixture Model (AGMM) were completely explained. A discussion about a new technique using the theory of Fractional Covariance Matrix (FCM), named Fractional Gaussian Mixture Model (FGMM), was initiated, restricted to GMMs implemented using diagonal covariance matrices. In the last chapter the experiments were detailed and its results were shown (also present in the appendices). \chapterref{experiments} described the MIT Mobile Device Speaker Verification Corpus (MIT-MDSCV), how the systems were implemented and the issues discovered. The speaker identification experiment was performed using GMM and FGMM, with the second providing inferior results. For speaker verification, the experimentation was executed using GMM and AGMM. The AGMM technique proved to be useful, showing results almost as good as the results from verification using GMM. The speaker models were generated using 4 combinations of adaptations, all of them with the means present. For all experiments, differences in performance depending on the environment of operation were observed. More robust systems were conceived when the GMM was trained with utterances from all environments, what proved to be consistent with a approach focused in real world problems.

Future studies about FGMM are necessary. Other implementations must be made in order to compare to the system described in this report. Also, an investigation on proper values of $r$ would help to understand if the lower performance was derived from a flaw in the theory or in the calibration of this attribute. The breach in the convergence rule for the EM algorithm also demands further investigations. The results for AGMM verification lead to the pursuit of an investigation of speaker identification (in close and in open sets) using the same combinations of adaptations. Vocal Tract Length Normalization (VTLN) is a logical next step to construct more refined GMM-UBM systems, due to the possibility of better speaker-separability in the acoustic space.