\chapter{Speaker Recognition Systems}
\label{ch:speaker-recognition-systems}

Speaker recognition lies on the field of pattern classification, with the speaker's speech signal $\boldsymbol{Y}$ as input for a classifier. For an identification system, the classification is 1 to $N$ (one speech signal to be identified as belonging to one of $N$ enrolled speakers), while for a verification system the classification is 1 to 1 (a speaker with a claimed identity is either \textbf{enrolled} or \textbf{imposter}).

Automatic Speaker Recognition (ASR) systems are bayesian classifiers, using the following equation to calculate the probabilities of recognition:

\begin{equation}
    \postprob{\mathcal{S}}{\boldsymbol{Y}} = \frac{\postpdf{\boldsymbol{Y}}{\mathcal{S}} \prob{\mathcal{S}}}{\pdf{\boldsymbol{Y}}},
    \label{eq:bayes_equation}
\end{equation}

\noindent where $\mathcal{S}$ is the speaker who produced $\boldsymbol{Y}$. As all speakers are considered equally probable, the \emph{a priori} probability $\prob{\mathcal{S}}$ can be removed with no loss, along with the \emph{evidence} $\pdf{\boldsymbol{Y}}$ (just used for normalization). \equationref{bayes_equation} is then replaced by $\postpdf{\boldsymbol{Y}}{\mathcal{S}}$, due to

\begin{equation}
    \postprob{\mathcal{S}}{\boldsymbol{Y}} \sim \postpdf{\boldsymbol{Y}}{\mathcal{S}}.
    \label{eq:bayes_equation_simplified}
\end{equation}

\section{Basic Concepts}
\label{sec:basic-concepts}

Before start the discussion about the types of ASR systems, two basic concepts (\textbf{utterance} and \textbf{features}) must be elucidated.

\subsection{Utterance}

An utterance is a piece of speech produced by a speaker. It may be a word, a statement or any vocal sound. The terms \emph{utterance} and \emph{speech signal} sometimes are used interchangeably, but from herenow speech signal is defined as an utterance recorded and digitalized. The speech signal is the input for an ASR system.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{chapters/speaker-recognition-systems/speech_signal}
    \caption{Speech signal for the utterance ``karen livescu", from the corpus defined in \refbib{Woo, Park \& Hazen}{woo.park.hazen.2006}.}
    \label{fig:speech_signal}
\end{figure}

\subsection{Features}

The raw speech signal is unfit to be used by the classifier in an ASR system. For a correct processing, the representative characteristics (i.e., features) from the speaker's vocal tract are extracted, what reduces the number of variables the system needs to deal with (leading to a simpler implementation) and performs a better evaluation (prevents the curse of dimensionality). Due to the stationary properties of the speech signal when analyzed in a short period of time, it is divided in overlapping frames of small and predefined length, to avoid ``loss of significance", \refbib{Davis \& Mermelstein}{davis.mermelstein.1980}, \refbib{Rabiner \& Schafer}{rabiner.schafer.2007}. This extraction is executed by the MFCC algorithm, explained in details in \chapterref{feature-extraction}.

\section{Speaker Identification}
\label{sec:speaker-identification}

Given a speech signal $\boldsymbol{Y}$ spoken by an arbitrary speaker $\mathcal{S}$, the task of identify $\mathcal{S}$ as a particular $\mathcal{S}_i$ from $\boldsymbol{\mathcal{S}}$ (set of enrolled users) is given by the following equation:

\begin{equation}
    i = \arg_j\max\postpdf{\boldsymbol{Y}}{\mathcal{S}_j} \implies \mathcal{S} \gets \mathcal{S}_i,
    \label{eq:classification_speaker_identification}
\end{equation}

\noindent for $j = 1, ..., N$ (where $N$ is the size of $\boldsymbol{\mathcal{S}}$). The high level speech $\boldsymbol{Y}$ in $\postpdf{\boldsymbol{Y}}{\mathcal{S}}$ is replaced by the sequence $\boldsymbol{X}$ of features, extracted from $\boldsymbol{Y}$, in \equationref{classification_speaker_identification}, a proper way to represent the signal's characteristics.

\subsection{Training}

The features are used to train statistical models for the speakers. Each speaker $\mathcal{S}_j$ is represented by a model $\lambda_j$, generated using only features extracted from this particular speaker.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{chapters/speaker-recognition-systems/speaker-recognition-training}
    \caption{The statistical model of $\mathcal{S}$ is created from the speech signal $\boldsymbol{Y}$, \refbib{Bimbot et. al.}{bimbot.et.al.2004}.}
    \label{fig:speaker-recognition-training}
\end{figure}

The idea behind the training stage is to make $\lambda_j$ ``memorize" the distinct characteristics present in $\mathcal{S}_j$'s vocal tract that provide the best representation. The SSGMM, initially referenced in \sectionref{gmm} and described in details in \chapterref{gmm}, is a perfect choice to model the speakers.

\subsection{Test}

The system test is performed replacing the speakers $\mathcal{S}_j$ in \equationref{classification_speaker_identification} by their models $\lambda_j$ (and $\boldsymbol{Y}$ by $\boldsymbol{X}$, as previously stated), leading to

\begin{equation}
    i = \arg_j\max\postpdf{\boldsymbol{X}}{\lambda_j} \implies \mathcal{S} \gets \mathcal{S}_i,
    \label{eq:speaker_identification}
\end{equation}

\noindent where the $\lambda_j$ with the highest likelihood has its identity assigned to $\mathcal{S}$. The main disadvantage this system presents is that every $\boldsymbol{X}$ must be tested against every $\mathcal{S}_j$ from $\boldsymbol{\mathcal{S}}$, what demands a high amount of time.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{chapters/speaker-recognition-systems/speaker-identification}
    \caption{Speaker identification test, \refbib{Reynolds}{reynolds.1995a}.}
    \label{fig:speaker_identification}
\end{figure}

\section{Speaker Verification}
\label{sec:speaker-verification}

If a speaker $\mathcal{S}$ claims to be a particular user $\mathcal{S}_{C}$ from $\boldsymbol{\mathcal{S}}$, the strength of this claim resides on how similar the features in $\boldsymbol{X}$ are to the features from $\mathcal{S}_{C}$ used to model the system. Then, a simple equation

\begin{equation}
    \postpdf{\boldsymbol{X}}{\mathcal{S}_{C}} \verifytestB{\alpha}{\mathcal{S}}
    \label{eq:decision_speaker_verification}
\end{equation}

\noindent where $\alpha$ is an arbitrary coefficient, should be enough. However, a subset of enrolled speakers may have vocal similarities or the features in $\boldsymbol{X}$ may be common to a large number of users, leading to a misclassification of an imposter as a registered speaker (a false detection). To reduce the error rate, the system must determine not only if $\boldsymbol{X}$ is similar to the claimed speaker's features, but also its similarities to a set composed of all other enrolled speakers' features and compare the likelihoods.

\subsection{Likelihood Ratio Test}

Given the sequence $\boldsymbol{X}$ of features, and assuming it was produced by only one speaker, the detection\footnote{the terms verification and detection are used interchangeably} task can be restated as a basic test between two hypoteses, \refbib{Reynolds}{reynolds.1995b}:

\begin{description}\itemsep0pt
    \item $H_0$: $\boldsymbol{X}$ is from the claimed speaker $\mathcal{S}_{C}$;
    \item $H_1$: $\boldsymbol{X}$ is \underline{not} from the claimed speaker $\mathcal{S}_{C}$.
\end{description}

\noindent The optimum test to decide which hypotesis is valid is the \textbf{likelihood ratio test} between both likelihoods $\postpdf{\boldsymbol{X}}{H_0}$ and $\postpdf{\boldsymbol{X}}{H_1}$, \refbib{Reynolds, Quatieri \& Dunn}{reynolds.quatieri.dunn.2000},

\begin{equation}
    \frac{\postpdf{\boldsymbol{X}}{H_0}}{\postpdf{\boldsymbol{X}}{H_1}} \verifytestB{\Theta}{H_0}
    \label{eq:likelihood-ratio-test}
\end{equation}

\noindent where the decision threshold for accepting or rejecting $H_0$ is $\Theta$ (a low $\Theta$ generates a more permissive system, while a high $\Theta$, a more restrictive). Applying the logarithm, the behavior of the likelihood ratio is maintained and \equationref{likelihood-ratio-test} is replaced by the \textbf{log-likelihood ratio}

\begin{equation}
    \Lambda(\boldsymbol{X}) = \log \postpdf{\boldsymbol{X}}{H_0} - \log \postpdf{\boldsymbol{X}}{H_1}.
    \label{eq:log-likelihood-ratio-test}
\end{equation}

\subsection{Training}

Once the features are extracted from the speech signal, they are used to train the models $\lambda_{C}$ and $\lambda_{\overline{C}}$ for $H_0$ and $H_1$, respectively. A high-level demonstration of the training of $\lambda_{C}$ is shown in \figureref{speaker-recognition-training}.

Due to $\lambda_{C}$ be a model of $\mathcal{S}_{C}$, the features used for training (i.e., estimate $p(\boldsymbol{X}|\lambda_{C})$) are extracted from speech signals produced by $\mathcal{S}_{C}$. The model $\lambda_{\overline{C}}$, however, is not well-defined. It should be composed of the features extracted from speech signals from all other speakers except $\mathcal{S}_{C}$, but creating a single $\lambda_{\overline{C}}$ for each speaker is complicated and with no expressive gain. Instead, what is normally done is use all speakers to generate a background model $\lambda_{bkg}$, \refbib{Reynolds}{reynolds.1997}, in which the presence of each $\mathcal{S}_{C}$ weights approximately the same.

\subsection{Test}

As seen in \equationref{log-likelihood-ratio-test}, the decision process is based on a function \emph{Score}. Replacing each $H_i$, for $i \in \{C, bkg\}$, by its corresponding model, the likelihood of a $\lambda_i$ given $\boldsymbol{X} = \{\dvec{x}_1, \dots, \dvec{x}_T\}$ can be written as

\begin{equation}
    p(\boldsymbol{X}|\lambda_i) = \prod_{t=1}^T p(\dvec{x}_t|\lambda_i).
    \label{eq:likelihood-prod}
\end{equation}

\noindent Using the logarithm function, \equationref{likelihood-prod} is replaced by

\begin{equation}
    \log p(\boldsymbol{X}|\lambda_i) = \frac{1}{T} \sum_{t=1}^T \log p(\dvec{x}_t|\lambda_i),
    \label{eq:log-likelihood-sum}
\end{equation}

\noindent where the term $\frac{1}{T}$ is inserted\footnote{\equationref{log-likelihood-sum} is not an accurate application of the $\log$ function to \equationref{likelihood-prod}, but an engineering solution.} to normalize the log-likelihood to the duration of the speech signal. That said, the likelihood ratio given by \equationref{log-likelihood-ratio-test} becomes

\begin{equation}
    \Lambda(\boldsymbol{X}) = \log p(\boldsymbol{X}|\lambda_{C}) - \log p(\boldsymbol{X}|\lambda_{bkg}),
    \label{eq:score_of_X}
\end{equation}

\noindent and the speaker is accepted if $\Lambda(\boldsymbol{X}) \geq \theta$, for an arbitrary value of $\Theta$, with $\theta = \log\Theta$.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{chapters/speaker-recognition-systems/speaker-verification}
    \caption{Likelihood-ratio-based speaker verification test, \refbib{Bimbot et. al.}{bimbot.et.al.2004}.}
    \label{fig:speaker-verification}
\end{figure}