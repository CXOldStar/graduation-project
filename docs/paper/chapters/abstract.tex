\chapter*{Abstract}
\label{ch:abstract}

This paper is a report of the implementation of Automatic Speaker Recognition (ASR) systems. The systems perform either identification or verification of speakers, regardless of the message contained in the speech produced. The utterances provided by the MIT Mobile Device Speaker Verification Corpus (MIT-MDSCV) database, produced by several enrolled and imposter speakers, are parameterized by the Mel-Frequency Cepstral Coefficient (MFCC) feature extraction process, using Cepstral Mean Subtraction (CMS) to reduce the disturbing channel effect and delta coefficients to improve the parametrization, and fed to Gaussian Mixture Models (GMMs) to create proper representations. The GMMs are divided in three categories: Single Speaker Gaussian Mixture Model (SSGMM), Single Speaker Adapted Gaussian Mixture Model (SSAGMM) and Single Speaker Fractional Gaussian Mixture Model (SSFGMM). Speaker identification experiments are performed using the first and the third models, while speaker verification uses the first and the second, along with an Universal Background Model (UBM) to perform a likelihood ratio test. The Fractional Gaussian Mixture Model (FGMM) is an initial investigation of the application of Fractional Covariance Matrix (FCM) to GMM. The experiments are exhibited plotting the performance rates over sizes of mixture, separated by different configurations of noisy environments. Additionally, the speaker verification results are shown using Detection Error Tradeoff (DET) curves, plotting the false rejection rate over the false detection rate.
\\

\noindent \textbf{Keywords:} Automatic Speaker Recognition, speaker identification, speaker verification, text-independent, MIT Mobile Device Speaker Verification Corpus, Mel-Frequency Cepstral Coefficient, Cepstral Mean Subtraction, Gaussian Mixture Models, Bayesian adaptation, Fractional Gaussian Mixture Model, Universal Background Model, likelihood ratio test, Fractional Covariance Matrix.